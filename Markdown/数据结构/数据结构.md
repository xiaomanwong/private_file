---
title: 数据结构
tag: 数据结构
category:算法与数据结构
---

## 数组

是一片物理上连续的大小确定的存储空间

数组查询速度快，是因为其在内存上是一段连续的内存空间，因此会有一个内存地址指向，每创建一个对象（Object），也就是要存储的值，占 4 个字节，通过 index * 4，在加上初始地址，计算的来的值，可以快速的定位到目标值，获取相应数据。

利用索引进行查询速度快，无法真正的删除

<!-- more -->

## List

具有连续有序性，可重复性，可扩容性，访问比较便捷

### ArrayList

**原理与特点**

实际上是对数组的一种封装，具备数组存储上空间连续及查找速度快的特性，并且顺序上也连续；但因为顺序上的连续，就造成了其删除和插入数据较慢的特性，因为顺序上的连续，所以在插入和删除时，为保证连续性，需要对数组的内容进行移动，大大增加了数据的操作性。

```java
    public void add(int index, E element) {
        if (index > size || index < 0)
            throw new IndexOutOfBoundsException(outOfBoundsMsg(index));

        ensureCapacityInternal(size + 1);  // Increments modCount!!
        // 移位操作
        System.arraycopy(elementData, index, elementData, index + 1,
                         size - index);
        elementData[index] = element;
        size++;
    }
 	public E remove(int index) {
        if (index >= size)
            throw new IndexOutOfBoundsException(outOfBoundsMsg(index));

        modCount++;
        E oldValue = (E) elementData[index];

        int numMoved = size - index - 1;
        if (numMoved > 0)
            // 移位操作
            System.arraycopy(elementData, index+1, elementData, index,
                             numMoved);
        elementData[--size] = null; // clear to let GC do its work

        return oldValue;
    }
```

**扩容机制：**

`ArrayList` 的默认长度是 10， 当数据总量超过容器时，会进行一次扩容操作，且每次扩容 50%。

```java
private void grow(int minCapacity) {
    // overflow-conscious code
    int oldCapacity = elementData.length;
    // oldCapacity >> 1 等价于  oldCapacity / 2
    int newCapacity = oldCapacity + (oldCapacity >> 1);
    if (newCapacity - minCapacity < 0)
        newCapacity = minCapacity;
    if (newCapacity - MAX_ARRAY_SIZE > 0)
        newCapacity = hugeCapacity(minCapacity);
    // minCapacity is usually close to size, so this is a win:
    elementData = Arrays.copyOf(elementData, newCapacity);
}
```



### LinkedList

是系统为我们提供的在物理上不连续，逻辑上连续的一个假象的数据片段。其内部实现是通过链表的方式，没一个元素都被封装成一个双向 `node` 节点，并绑定前一个和下一个节点的方式，来保证物理上连续。

因采用链表的结构，因此也灭有长度限制，也不存在扩容机制，可以无限长。

因此，他不向数组的可以快速定位数据，当获取数据时，需要根据节点位置，遍历才能获得，因此其查询速度很慢

```java
public E get(int index) {
    checkElementIndex(index);
    return node(index).item;
}
Node<E> node(int index) {
    // 从前面查找
    if (index < (size >> 1)) {
        Node<E> x = first;
        for (int i = 0; i < index; i++)
            x = x.next;
        return x;
    } else {
        // 从后面查找
        Node<E> x = last;
        for (int i = size - 1; i > index; i--)
            x = x.prev;
        return x;
    }
}	
```

但他的插入和删除就很方便，插入和删除时，只需要断开链表，重新将新数据的头尾互相指向即可。

```java
   //插入数据
    public void add(int index, E element) {
        if (index == size)
            linkLast(element);
        else
            // 插入时，有时也需要遍历，这里可以忽略
            linkBefore(element, node(index));
    }

	void linkLast(E e) {
        final Node<E> l = last;
        final Node<E> newNode = new Node<>(l, e, null);
        last = newNode;
        if (l == null)
            first = newNode;
        else
            l.next = newNode;
        size++;
        modCount++;
    }
    void linkBefore(E e, Node<E> succ) {
        // assert succ != null;
        final Node<E> pred = succ.prev;
        final Node<E> newNode = new Node<>(pred, e, succ);
        succ.prev = newNode;
        if (pred == null)
            first = newNode;
        else
            pred.next = newNode;
        size++;
        modCount++;
    }
// 移除数据
	private E unlinkFirst(Node<E> f) {
        // assert f == first && f != null;
        final E element = f.item;
        final Node<E> next = f.next;
        f.item = null;
        f.next = null; // help GC
        first = next;
        if (next == null)
            last = null;
        else
            next.prev = null;
        size--;
        modCount++;
        return element;
    }

    /**
     * Unlinks non-null last node l.
     */
    private E unlinkLast(Node<E> l) {
        // assert l == last && l != null;
        final E element = l.item;
        final Node<E> prev = l.prev;
        l.item = null;
        l.prev = null; // help GC
        last = prev;
        if (prev == null)
            first = null;
        else
            prev.next = null;
        size--;
        modCount++;
        return element;
    }
```

### Vector

和 ArrayList 几乎一样，区别在于 Vector 是线程安全的，在插入、删除等操作，其方法都是 `synchronized`，因此性能比 `ArrayList` 差，每次扩容申请双倍空间也可以自定义。

## Set

具有不可重复性，无序性，*不可查找的特点*

### HashSet

`HashSet` 的内部使用 `HashMap` 来存储数据，即 `add` 时，将元素当作 `HashMap ` 的 `Key` 来使用，这也符合 `Set` 集合不可重复性的特点。

此类集合不可以直接获取容器中的 value， 可通过遍历 *迭代器*  来获取全部元素。但不能多线程操作，此类容器都是可快速失败的，即当我们正在遍历时，如果原数据被修改，则会立即停止，并抛出 `ConCurrentException` 。

### LinkedHashSet

同样根据 hashCode 来决定元素的存储位置，同时又具有 链表的特点，在迭代遍历时，可以获取到列表顺序。

**List 和 Set 的区别**

- 是否允许数据元素重复存在，在 List 中允许插入重复的元素，Set 集合不允许
- 元素的先后存放顺序 List 是一个有序的集合，会保留元素的插入顺序， Set 是无序集合
- List 可以通过下标来访问元素， 而 Set 不能



## HashMap

**数组** 和 **单链表** 的组合， 数组用来存储 key，链表用来存储实际的 value

### put(K key, V value);

当存放一个数值时，会先对 key 值进行 hash 运算得到 Hash 值，

当链表为空时，通过 `resize()` 函数帮我创建一个新链表，默认长度为 16 （1 << 4，为 2 的次幂数，这里和扩容机制有关）；(由于 Hash Map 的长度机制限制，所以 table 的初始化工作，在 put 真正使用这个数据时才去创建，避免了性能上的损耗)

当链表不为空，通过 hash 值，从数组中获取到对应的节点对象，如果对象为空，则创建一个新的节点；如果节点不为空，说明这个 key 被赋值过，因此将新的 value 赋值给该节点。

```java
/**
* 装箱过程，计算 hash 值的过程。
* 
*/
static final int hash(Object key) {
        int h;
        return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}
final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) {
        Node<K, V>[] tab;
        Node<K, V> p;
        int n, i;
        if ((tab = table) == null || (n = tab.length) == 0)
            n = (tab = resize()).length;
     	// tab[i = (n - 1) & hash] 
    	// n 是数组的长度，经过 & 和 hash 值的位运算（模运算：求余数的运算，等价于=> （hash % n）），获得该元素在数组中的索引
        if ((p = tab[i = (n - 1) & hash]) == null)
            tab[i] = newNode(hash, key, value, null);
        else {
            Node<K, V> e;
            K k;
            if (p.hash == hash &&
                    ((k = p.key) == key || (key != null && key.equals(k))))
                e = p;
            else if (p instanceof TreeNode)
                e = ((TreeNode<K, V>) p).putTreeVal(this, tab, hash, key, value);
            else {
                for (int binCount = 0; ; ++binCount) {
                    if ((e = p.next) == null) {
                        p.next = newNode(hash, key, value, null);
                        if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
                            treeifyBin(tab, hash);
                        break;
                    }
                    if (e.hash == hash &&
                            ((k = e.key) == key || (key != null && key.equals(k))))
                        break;
                    p = e;
                }
            }
            if (e != null) { // existing mapping for key
                V oldValue = e.value;
                if (!onlyIfAbsent || oldValue == null)
                    e.value = value;
                afterNodeAccess(e);
                return oldValue;
            }
        }
        ++modCount;
        if (++size > threshold)
            resize();
        afterNodeInsertion(evict);
        return null;
    }
```

### **Hash 碰撞/冲突**

在求模运算过程中，存在多对一的情况，即不同的 Hash 值，可能会计算出相同的索引值

**解决方案**：

**链表法：** 当发生 Hash 碰撞/冲突，即不同的 hash 值，最终计算出了相同的索引值，如果索引对应的位置数据为 null， 则直接创建新节点，如果不为 null， 则采用前插/后插的方案，插入到链表当中，当通过 `get()` 函数获取数据时，拿到一个链表，就遍历，找到 `hash` 值相同的那个节点，并返回。

**避免冲突**：

阈值，为保证在尽可能长的情况下，保证 hash 不会冲突。即当发生时，就扩容。

**扩容方案：**

加载因子：`loadFactor` 默认值是 0.75

阈值：与加载因子有关，通过加载因子和 HashMap 的长度计算而来，有阈值就一定会有浪费，因此 25% 的内存内浪费掉，在 Android  使用空间换时间。

HashMap 的默认长度是 16，其长度，一定是 2 的次幂，目的是为了减少 Hash 的碰撞。

> 比如：
>
> length1 = 10，(非 2 的次幂)，对应的二进制数是 1001
>
> length2 = 16(2 的 4 次幂)，对应的二进制数是 1111
>
> 当产生一个 hash 值，为 6（0110）时， (n - 1) & hash ，length1 位运算之后的结果是 0000， length2 位运算之后的结果是 0110
>
> 当产生一个 hash 值，为 7（0111）时， (n - 1) & hash ，length1 位运算之后的结果是 0001， length2 位运算之后的结果是 0111
>
> 由此我们可以看出，影响运算结果的因素是 (1001) 中间的两位数字，而使用 (1111) 计算的结果，与四位数字都有关系（也就是说 数字 1 不会影响结果的计算），因此使用 2 的次幂为长度的目的就是为了减少 Hash 值的碰撞



当链表长度，以及其他索引对应的链表总长度大于阈值时，开始扩容。

当扩容发生时，HashMap 的长度就发生了变化，扩容前的数据的模运算就发生了改变，因此在扩容后，需要使用新的长度对所有的原有数据，进行 hash 计算，因此会发生性能上的损耗。因此在使用时，我们要尽量避免 HashMap 发生扩容。

开发时，需要我们去尽量评估容量，当我们创建一个 HashMap，并传入一个非 2 的次幂值时，系统会帮我们寻找一个比当前值大的最近的 2 的次幂值，来给 HashMap 作为初始值。一个简单的公式用来计算 HashMap 的初始容 量=> {size / 3 * 4 + 1}

## SparseArray

**原理与特点**

由 **双数组** 构成，两个数组分别存储 `Key` 和  `Value` ，并一一对应。

查询速度快，删除快，插入慢（随着数据越来越大，插入的性能也会提升）

通过获取 key 的索引找到其对应的 value 值，也就具备了 **查询速度快** 的特点（也是数组的特点）

删除元素时，仅将元素标记位 **"DELETE"** 状态，不发生移位等操作，因此速度上会比 `ArrayList` 快

因为是标记为 "DELETE" ，因此算法是可以达到复用，再利用二分查找，被标记为 "DELETE" 的数据，可以直接复用，不会涉及到数组的位移，因此会越用越快。

缺点是，Key 只能是 `int` 类型数据。

```java
    public void put(int key, E value) {
        // 二分查找，快速定位传入的 key 所在位置
        int i = ContainerHelpers.binarySearch(mKeys, mSize, key);
        // 如果存在，直接替换同位置数据
        if (i >= 0) {
            mValues[i] = value;
        } else {
            // 不存在时，如果当前位置被标记为 DELETE 状态（未被使用），则直接给 key 和 value 数组赋值
            i = ~i;
            if (i < mSize && mValues[i] == DELETED) {
                mKeys[i] = key;
                mValues[i] = value;
                return;
            }
            if (mGarbage && mSize >= mKeys.length) {
                gc();
                // Search again because indices may have changed.
                i = ~ContainerHelpers.binarySearch(mKeys, mSize, key);
            }
            // 扩容机制，2倍
            mKeys = GrowingArrayUtils.insert(mKeys, mSize, i, key);
            mValues = GrowingArrayUtils.insert(mValues, mSize, i, value);
            mSize++;
        }
    }
	public static int[] insert(int[] array, int currentSize, int index, int element) {
       int[] newArray = new int[growSize(currentSize)];
        System.arraycopy(array, 0, newArray, 0, index);
        newArray[index] = element;
        System.arraycopy(array, index, newArray, index + 1, array.length - index);
        return newArray;
    }
 	public static int growSize(int currentSize) {
        // 2 倍扩容机制
        return currentSize <= 4 ? 8 : currentSize * 2;
    }

    // 移除数据，仅标记 DELETE 状态
    public void delete(int key) {
        int i = ContainerHelpers.binarySearch(mKeys, mSize, key);

        if (i >= 0) {
            if (mValues[i] != DELETED) {
                mValues[i] = DELETED;
                mGarbage = true;
            }
        }
    }

```

**扩容机制：**

同样的，初始长度为 10， 每次扩容，为当前容量的 2 倍。

## ArrayMap

是Hash Map 和 Sparse Array 的合计，具备他们的双重特性，使用 `hashcode` 作为 key，弥补了 `SparseArray` 只能是 `int` 型。使用双数组的形式，又弥补了 `HashMap` 的对内存消耗的问题。

## LinkedHashMap

是 `HashMap` 的子类， `put`  和 `remove` 函数使用的就是 `HashMap` 的，没有太大却别，主要区别在于 `get` 函数， `LinkedHashMap` 在每次 `get` 出一个数据后，会将这个数据放在链表的尾部。

`LinkedHashMap` 的应用，在 `LRUCache` 和 `DiskLRUCache` 中使用，其算法名称 *最少/最小使用算法* ，也就是说，利用了 `LinkedHashMap` 的 `get` 函数的特性，计算出链表头部的数据被使用的次数最少，当容器长度达到最大值时，就将链表头部的数据移除。



## 队列 Queue 和 栈 Stack

* 队列的特点是 *先入先出*
* 栈的特点是 *先入后出* 

### 栈

**特点：** 后进先出； 所有的操作都是围绕栈顶部来完成

算法的基本思想：

可以用一个单链表来实现

只关心上一次的操作

处理完上一次操作后，能在 O(1) 时间内查找到更前一次的操作

```java
// 查找下一个比自己大的数的距离
public void stackSwap(int[] nums) {
    
    // 定义一个栈，用来缓存当前的最大值的索引
    Stack<Integer> stack = new Stack<>();
    // 定义一个数组，用来存储对应数据的间距
    int[] interval = new int[nums.length];
    
    for(int i = 0; i < nums.length; i++) {
       	if(!stack.empty()){
            // 因为会对栈进行操作，长度会改变，如果不先取，会导致循环跳位
            int size = stack.size();
            for(int j  = 0; j < size; j++) {
                // 拿出栈顶数据的索引
                int topIndex = stack.peek();
                if(nums[i] > num[topIndex]) {
                    interval[topIndex] = i - topIndex;
                    stack.pop();
                }
            }
        }
        // 如果为空，或者栈顶数据比但前数据大，则将数据直接压入
        // 或找不到一个比当前数据大的数据时，将当前数据压入栈
        stack.push(i);
    }
    
}
```

### 队列

和栈不同，队列的最大特点是先进先出（FIFO），就好像按顺序排队一样。对于队列的数据来说，我们只允许在队尾查看和添加数据，在队头查看和删除数据。

实现：可以借助双链表来实现队列。双链表的头指针允许在队头查看和删除数据，而双链表的尾指针允许我们在队尾查看和添加数据。

应用场景：直观来看，当我们需要按照一定的顺序来处理数据，而该数据的数据量在不断地变化的时候，则需要队列来帮助解题。在算法面试题当中，广度优先搜索（Breadth-First Search）是运用队列最多的地方。